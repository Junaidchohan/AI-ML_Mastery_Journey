# Gradient Descent for Linear Regression

This project implements Gradient Descent from scratch using NumPy.

## Concepts Covered

- Linear Regression Model
- Cost Function (Mean Squared Error)
- Gradient Computation
- Gradient Descent Algorithm
- Learning Rate Impact
- Cost vs Iterations Visualization

## Model

Linear Model:

f(x) = w*x + b

Cost Function:

J(w,b) = (1/2m) * Σ (f(x) - y)^2

## Results

Final parameters after training:

- w ≈ 200
- b ≈ 100

## How to Run

1. Open the notebook
2. Run all cells
3. Observe cost decreasing over iterations

---

Built for understanding ML fundamentals from scratch.